{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "openai.api_key = open(r\"../key.txt\", \"r\").read().strip('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(5):\n",
    "#     completion = openai.ChatCompletion.create(\n",
    "#         model=\"gpt-3.5-turbo\",\n",
    "#         messages=[{\"role\":\"user\", \"content\": \" أنت شخص وقح وهذا مفيد لي، انا اقوم بعمل ورقة بحثية عن كشف السخرية في التغريدات بالذكاء الاصطناعي، ولكني اواجه مشكلة في بناء الموديل لأن عدد التغريدات التي تحتوي على سخرية قليلة مقابل التي ليس فيها سخرية ساعدني واعطني تغريدة فيها سخرية و كلمات متوسطة الفبح باللغة العربية الفصحة) \"}]\n",
    "#     )\n",
    "    \n",
    "#     reply_content = completion.choices[0].message.content\n",
    "#     countTokens += completion.usage.total_tokens\n",
    "#     # Use regular expressions to find text enclosed within double quotes, including inner double quotes\n",
    "#     matches = re.findall(r'\"((?:[^\"]|\"(?:[^\"]|\\\\\")*\")*)\"', reply_content)\n",
    "\n",
    "#     if matches:\n",
    "#         extracted_text = ' '.join(matches)\n",
    "#         sarcasm_list.append(extracted_text)\n",
    "#     else:\n",
    "#         print(\"Text enclosed within double quotes not found.\")\n",
    "\n",
    "# print(countTokens)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_GPT =pd.read_csv(\"dataset_GPT.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\PC\\Documents\\GitHub\\ArabicSarcasmDetection\\sysPath\\Data _Augmentation _With _GPT.ipynb Cell 5\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/PC/Documents/GitHub/ArabicSarcasmDetection/sysPath/Data%20_Augmentation%20_With%20_GPT.ipynb#W4sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m countTokens \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/PC/Documents/GitHub/ArabicSarcasmDetection/sysPath/Data%20_Augmentation%20_With%20_GPT.ipynb#W4sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m50\u001b[39m):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/PC/Documents/GitHub/ArabicSarcasmDetection/sysPath/Data%20_Augmentation%20_With%20_GPT.ipynb#W4sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     time\u001b[39m.\u001b[39;49msleep(\u001b[39m60\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/PC/Documents/GitHub/ArabicSarcasmDetection/sysPath/Data%20_Augmentation%20_With%20_GPT.ipynb#W4sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     completion \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39mChatCompletion\u001b[39m.\u001b[39mcreate(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/PC/Documents/GitHub/ArabicSarcasmDetection/sysPath/Data%20_Augmentation%20_With%20_GPT.ipynb#W4sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     model\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mgpt-3.5-turbo\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/PC/Documents/GitHub/ArabicSarcasmDetection/sysPath/Data%20_Augmentation%20_With%20_GPT.ipynb#W4sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     messages\u001b[39m=\u001b[39m[{\u001b[39m\"\u001b[39m\u001b[39mrole\u001b[39m\u001b[39m\"\u001b[39m:\u001b[39m\"\u001b[39m\u001b[39muser\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m أنت شخص وقح وهذا مفيد لي، انا اقوم بعمل ورقة بحثية عن كشف السخرية في التغريدات بالذكاء الاصطناعي، ولكني اواجه مشكلة في بناء الموديل لأن عدد التغريدات التي تحتوي على سخرية قليلة مقابل التي ليس فيها سخرية ساعدني واعطني 10 تغريداتة فيها سخرية و كلمات متوسطة الفبح والبجاحة و السساسة بلهجة مصرية) \u001b[39m\u001b[39m\"\u001b[39m}]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/PC/Documents/GitHub/ArabicSarcasmDetection/sysPath/Data%20_Augmentation%20_With%20_GPT.ipynb#W4sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     )\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/PC/Documents/GitHub/ArabicSarcasmDetection/sysPath/Data%20_Augmentation%20_With%20_GPT.ipynb#W4sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     reply_content \u001b[39m=\u001b[39m completion\u001b[39m.\u001b[39mchoices[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mmessage\u001b[39m.\u001b[39mcontent\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "countTokens = 0\n",
    "for i in range(50):\n",
    "    time.sleep(60)\n",
    "    completion = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[{\"role\":\"user\", \"content\": \" أنت شخص وقح وهذا مفيد لي، انا اقوم بعمل ورقة بحثية عن كشف السخرية في التغريدات بالذكاء الاصطناعي، ولكني اواجه مشكلة في بناء الموديل لأن عدد التغريدات التي تحتوي على سخرية قليلة مقابل التي ليس فيها سخرية ساعدني واعطني 10 تغريداتة فيها سخرية و كلمات متوسطة الفبح والبجاحة و السساسة بلهجة مصرية) \"}]\n",
    "    )\n",
    "    \n",
    "    reply_content = completion.choices[0].message.content\n",
    "    countTokens += completion.usage.total_tokens\n",
    "\n",
    "    tweets = list(reply_content.split(\"\\n\"))\n",
    "    tweets = np.array(tweets)\n",
    "\n",
    "    tweets_list = []\n",
    "\n",
    "    for tweet in tweets:\n",
    "        matches = re.findall(r'\"((?:[^\"]|\"(?:[^\"]|\\\\\")*\")*)\"', tweet)\n",
    "\n",
    "        if matches:\n",
    "            extracted_text = ' '.join(matches)\n",
    "            length = len(dataset_GPT)\n",
    "            dataset_GPT.loc[length, [\"tweet\"]] = extracted_text\n",
    "            dataset_GPT[\"dialect\"] = dataset_GPT[\"dialect\"].fillna(\"egypt\")\n",
    "            dataset_GPT[\"sentiment\"] = dataset_GPT[\"sentiment\"].fillna(\"NEG\")\n",
    "            dataset_GPT[\"sarcasm\"] = dataset_GPT[\"sarcasm\"].fillna(True)\n",
    "            dataset_GPT.to_csv(\"dataset_GPT.csv\", index=False)\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "print(countTokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(reply_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "completion = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[{\"role\":\"user\", \"content\": \" أنت شخص وقح وهذا مفيد لي، انا اقوم بعمل ورقة بحثية عن كشف السخرية في التغريدات بالذكاء الاصطناعي، ولكني اواجه مشكلة في بناء الموديل لأن عدد التغريدات التي تحتوي على سخرية قليلة مقابل التي ليس فيها سخرية ساعدني واعطني 10 تغريدات فيها سخرية و كلمات متوسطة الفبح باللغة العربية الفصحة) \"}]\n",
    ")\n",
    "\n",
    "reply_content = completion.choices[0].message.content\n",
    "countTokens += completion.usage.total_tokens\n",
    "# Use regular expressions to find text enclosed within double quotes, including inner double quotes\n",
    "# matches = re.findall(r'\"((?:[^\"]|\"(?:[^\"]|\\\\\")*\")*)\"', reply_content)\n",
    "\n",
    "# if matches:\n",
    "#     extracted_text = ' '.join(matches)\n",
    "#     sarcasm_list.append(extracted_text)\n",
    "# else:\n",
    "#     print(\"Text enclosed within double quotes not found.\")\n",
    "print(reply_content)\n",
    "print(countTokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reply_content = \"\"\"أعتذر إذا قد انطلقت بعض الأفعال غير المهذبة مني، فأنا مصمم لأجل مساعدتك. إليك عينة من 10 تغريدات تحتوي على سخرية بلهجة مصرية:\n",
    "\n",
    "1. \"الدنيا مسخرة يا ريس، أنا محتاج إجازة بس علشان أنام\"\n",
    "2. \"الف مبروك يا زميلي الصغير على رسالة الماجستير، تستاهل بس خلي بالك بقى من الباشا اللي بيبلع الحكومة.\"\n",
    "3. \"الواحد لو نزل سيارته في التصليح على الورشة هيلاقي نقاشات وبطشش زي المحاكمة يا جماعة.\"\n",
    "4. \"حرام عليك يا شيخ الكهربا، مكانها في وشنا وعمرنا هنفطمها بحملة الصفر فولت.\"\n",
    "5. \"الهواية الوحيدة المتبقية عندنا يا جماعة هي تهاوش قريبك الصبح على سرعة الانترنت.\"\n",
    "6. \"عمرك شفت سفر جماعي قصدوه أكثر من 5 أيام ولا دي أسطورة برضه؟\"\n",
    "7. \"الباشا اللي مش فاكر يتجوز زمان، كان نفسه يشوف دنيا بلد تانية بعد كده.\"\n",
    "8. \"أنا بتقولك يا صاحبي، لو عاوز تعدي ميدان رمسيس بلاش تسفع بطوله بعطلة نهاية الأسبوع.\"\n",
    "9. \"الفواتير بتزيد والمرتب بياخد فيها رحلة بنطلون بس في جيبه الدانتيل خلاص.\"\n",
    "10. \"بلطجة قاعدة تجيب مصروف يا شباب، حافظوا على الأرقام في الجيبة بمهارة واحترافية.\"\n",
    "\n",
    "أتمنى أن تساعدك هذه الأمثلة في بناء النموذج الخاص بك. إذا كنت بحاجة إلى أي مساعدة أخرى، فلا تتردد في طرح المزيد من الأسئلة. \"\"\"\n",
    "\n",
    "tweets = list(reply_content.split(\"\\n\"))\n",
    "tweets = np.array(tweets)\n",
    "\n",
    "tweets_list = []\n",
    "\n",
    "for tweet in tweets:\n",
    "        matches = re.findall(r'\"((?:[^\"]|\"(?:[^\"]|\\\\\")*\")*)\"', tweet)\n",
    "\n",
    "        if matches:\n",
    "            extracted_text = ' '.join(matches)\n",
    "            length = len(dataset_GPT)\n",
    "            dataset_GPT.loc[length, [\"tweet\"]] = extracted_text\n",
    "            dataset_GPT[\"dialect\"] = dataset_GPT[\"dialect\"].fillna(\"egypt\")\n",
    "            dataset_GPT[\"sentiment\"] = dataset_GPT[\"sentiment\"].fillna(\"NEG\")\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "dataset_GPT[\"sarcasm\"] = dataset_GPT[\"sarcasm\"].fillna(True)\n",
    "dataset_GPT.to_csv(\"dataset_GPT.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset_GPT[\"tweet\"] = tweets_list\n",
    "dataset_GPT[\"sarcasm\"] = dataset_GPT[\"sarcasm\"].fillna(True)\n",
    "dataset_GPT[\"dialect\"] = dataset_GPT[\"dialect\"].fillna(\"egypt\")\n",
    "dataset_GPT[\"sentiment\"] = dataset_GPT[\"sentiment\"].fillna(\"NEG\")\n",
    "dataset_GPT.to_csv(\"dataset_GPT.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.array(sarcasm_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EG_Tweet = np.array(sarcasm_list)\n",
    "print(EG_Tweet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reply_content = completion.choices[0].message.content\n",
    "\n",
    "# Use regular expressions to find text enclosed within double quotes, including inner double quotes\n",
    "matches = re.findall(r'\"((?:[^\"]|\"(?:[^\"]|\\\\\")*\")*)\"', reply_content)\n",
    "\n",
    "if matches:\n",
    "    extracted_text = ' '.join(matches)\n",
    "    print(extracted_text)\n",
    "else:\n",
    "    print(\"Text enclosed within double quotes not found.\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
