{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "openai.api_key = open(\"key.txt\", \"r\").read().strip('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(5):\n",
    "#     completion = openai.ChatCompletion.create(\n",
    "#         model=\"gpt-3.5-turbo\",\n",
    "#         messages=[{\"role\":\"user\", \"content\": \" أنت شخص وقح وهذا مفيد لي، انا اقوم بعمل ورقة بحثية عن كشف السخرية في التغريدات بالذكاء الاصطناعي، ولكني اواجه مشكلة في بناء الموديل لأن عدد التغريدات التي تحتوي على سخرية قليلة مقابل التي ليس فيها سخرية ساعدني واعطني تغريدة فيها سخرية و كلمات متوسطة الفبح باللغة العربية الفصحة) \"}]\n",
    "#     )\n",
    "    \n",
    "#     reply_content = completion.choices[0].message.content\n",
    "#     countTokens += completion.usage.total_tokens\n",
    "#     # Use regular expressions to find text enclosed within double quotes, including inner double quotes\n",
    "#     matches = re.findall(r'\"((?:[^\"]|\"(?:[^\"]|\\\\\")*\")*)\"', reply_content)\n",
    "\n",
    "#     if matches:\n",
    "#         extracted_text = ' '.join(matches)\n",
    "#         sarcasm_list.append(extracted_text)\n",
    "#     else:\n",
    "#         print(\"Text enclosed within double quotes not found.\")\n",
    "\n",
    "# print(countTokens)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_GPT =pd.read_csv(\"dataset_GPT.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "RateLimitError",
     "evalue": "Rate limit reached for default-gpt-3.5-turbo in organization org-IaPr9ajykOkgjn8eSUOvzvTj on requests per day. Limit: 200 / day. Please try again in 7m12s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32md:\\ArabicSarcasmDetection\\Data _Augmentation _With _GPT.ipynb Cell 5\u001b[0m line \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/ArabicSarcasmDetection/Data%20_Augmentation%20_With%20_GPT.ipynb#W4sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m10\u001b[39m):\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/ArabicSarcasmDetection/Data%20_Augmentation%20_With%20_GPT.ipynb#W4sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/ArabicSarcasmDetection/Data%20_Augmentation%20_With%20_GPT.ipynb#W4sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m         completion \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39;49mChatCompletion\u001b[39m.\u001b[39;49mcreate(\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/ArabicSarcasmDetection/Data%20_Augmentation%20_With%20_GPT.ipynb#W4sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m         model\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mgpt-3.5-turbo\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/ArabicSarcasmDetection/Data%20_Augmentation%20_With%20_GPT.ipynb#W4sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m         messages\u001b[39m=\u001b[39;49m[{\u001b[39m\"\u001b[39;49m\u001b[39mrole\u001b[39;49m\u001b[39m\"\u001b[39;49m:\u001b[39m\"\u001b[39;49m\u001b[39muser\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mcontent\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39m أنت شخص وقح وهذا مفيد لي، انا اقوم بعمل ورقة بحثية عن كشف السخرية في التغريدات بالذكاء الاصطناعي، ولكني اواجه مشكلة في بناء الموديل لأن عدد التغريدات التي تحتوي على سخرية قليلة مقابل التي ليس فيها سخرية ساعدني واعطني 10 تغريداتة فيها سخرية و كلمات متوسطة الفبح والبجاحة بلهجة خليجية) \u001b[39;49m\u001b[39m\"\u001b[39;49m}]\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/ArabicSarcasmDetection/Data%20_Augmentation%20_With%20_GPT.ipynb#W4sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m         )\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/ArabicSarcasmDetection/Data%20_Augmentation%20_With%20_GPT.ipynb#W4sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m         reply_content \u001b[39m=\u001b[39m completion\u001b[39m.\u001b[39mchoices[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mmessage\u001b[39m.\u001b[39mcontent\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/ArabicSarcasmDetection/Data%20_Augmentation%20_With%20_GPT.ipynb#W4sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m         countTokens \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m completion\u001b[39m.\u001b[39musage\u001b[39m.\u001b[39mtotal_tokens\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\openai\\api_resources\\chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m     24\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 25\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     26\u001b[0m     \u001b[39mexcept\u001b[39;00m TryAgain \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     27\u001b[0m         \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m time\u001b[39m.\u001b[39mtime() \u001b[39m>\u001b[39m start \u001b[39m+\u001b[39m timeout:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[1;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[0;32m    128\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[0;32m    129\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    136\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[0;32m    137\u001b[0m ):\n\u001b[0;32m    138\u001b[0m     (\n\u001b[0;32m    139\u001b[0m         deployment_id,\n\u001b[0;32m    140\u001b[0m         engine,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[0;32m    151\u001b[0m     )\n\u001b[1;32m--> 153\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[0;32m    154\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    155\u001b[0m         url,\n\u001b[0;32m    156\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[0;32m    157\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    158\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[0;32m    159\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[0;32m    160\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[0;32m    161\u001b[0m     )\n\u001b[0;32m    163\u001b[0m     \u001b[39mif\u001b[39;00m stream:\n\u001b[0;32m    164\u001b[0m         \u001b[39m# must be an iterator\u001b[39;00m\n\u001b[0;32m    165\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\openai\\api_requestor.py:298\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[1;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[0;32m    278\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    279\u001b[0m     method,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    286\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    287\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[0;32m    288\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_raw(\n\u001b[0;32m    289\u001b[0m         method\u001b[39m.\u001b[39mlower(),\n\u001b[0;32m    290\u001b[0m         url,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    296\u001b[0m         request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[0;32m    297\u001b[0m     )\n\u001b[1;32m--> 298\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response(result, stream)\n\u001b[0;32m    299\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\openai\\api_requestor.py:700\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[1;34m(self, result, stream)\u001b[0m\n\u001b[0;32m    692\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m    693\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response_line(\n\u001b[0;32m    694\u001b[0m             line, result\u001b[39m.\u001b[39mstatus_code, result\u001b[39m.\u001b[39mheaders, stream\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    695\u001b[0m         )\n\u001b[0;32m    696\u001b[0m         \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m parse_stream(result\u001b[39m.\u001b[39miter_lines())\n\u001b[0;32m    697\u001b[0m     ), \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    698\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    699\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m--> 700\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response_line(\n\u001b[0;32m    701\u001b[0m             result\u001b[39m.\u001b[39;49mcontent\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m    702\u001b[0m             result\u001b[39m.\u001b[39;49mstatus_code,\n\u001b[0;32m    703\u001b[0m             result\u001b[39m.\u001b[39;49mheaders,\n\u001b[0;32m    704\u001b[0m             stream\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    705\u001b[0m         ),\n\u001b[0;32m    706\u001b[0m         \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    707\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\openai\\api_requestor.py:765\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[1;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[0;32m    763\u001b[0m stream_error \u001b[39m=\u001b[39m stream \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m resp\u001b[39m.\u001b[39mdata\n\u001b[0;32m    764\u001b[0m \u001b[39mif\u001b[39;00m stream_error \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m rcode \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m:\n\u001b[1;32m--> 765\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_error_response(\n\u001b[0;32m    766\u001b[0m         rbody, rcode, resp\u001b[39m.\u001b[39mdata, rheaders, stream_error\u001b[39m=\u001b[39mstream_error\n\u001b[0;32m    767\u001b[0m     )\n\u001b[0;32m    768\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "\u001b[1;31mRateLimitError\u001b[0m: Rate limit reached for default-gpt-3.5-turbo in organization org-IaPr9ajykOkgjn8eSUOvzvTj on requests per day. Limit: 200 / day. Please try again in 7m12s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method."
     ]
    }
   ],
   "source": [
    "countTokens = 0\n",
    "for i in range(10):\n",
    "    while True:\n",
    "        try:\n",
    "            completion = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[{\"role\":\"user\", \"content\": \" أنت شخص وقح وهذا مفيد لي، انا اقوم بعمل ورقة بحثية عن كشف السخرية في التغريدات بالذكاء الاصطناعي، ولكني اواجه مشكلة في بناء الموديل لأن عدد التغريدات التي تحتوي على سخرية قليلة مقابل التي ليس فيها سخرية ساعدني واعطني 10 تغريداتة فيها سخرية و كلمات متوسطة الفبح والبجاحة بلهجة خليجية) \"}]\n",
    "            )\n",
    "            \n",
    "            reply_content = completion.choices[0].message.content\n",
    "            countTokens += completion.usage.total_tokens\n",
    "\n",
    "            tweets = list(reply_content.split(\"\\n\"))\n",
    "            tweets = np.array(tweets)\n",
    "\n",
    "            tweets_list = []\n",
    "\n",
    "            for tweet in tweets:\n",
    "                matches = re.findall(r'\"((?:[^\"]|\"(?:[^\"]|\\\\\")*\")*)\"', tweet)\n",
    "\n",
    "                if matches:\n",
    "                    extracted_text = ' '.join(matches)\n",
    "                    length = len(dataset_GPT)\n",
    "                    dataset_GPT.loc[length, [\"tweet\"]] = extracted_text\n",
    "                    dataset_GPT[\"dialect\"] = dataset_GPT[\"dialect\"].fillna(\"gulf\")\n",
    "                    dataset_GPT[\"sentiment\"] = dataset_GPT[\"sentiment\"].fillna(\"NEG\")\n",
    "                    dataset_GPT[\"sarcasm\"] = dataset_GPT[\"sarcasm\"].fillna(True)\n",
    "                    dataset_GPT.to_csv(\"dataset_GPT.csv\", index=False)\n",
    "                else:\n",
    "                    pass\n",
    "        except:\n",
    "            print(\"handling the error:.............\")\n",
    "            time.sleep(100)\n",
    "            continue\n",
    "        break\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "print(countTokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "أعتذر إذا قد انطلقت بعض الأفعال غير المهذبة مني، فأنا مصمم لأجل مساعدتك. إليك عينة من 10 تغريدات تحتوي على سخرية بلهجة مصرية:\n",
      "\n",
      "1. \"الدنيا مسخرة يا ريس، أنا محتاج إجازة بس علشان أنام\"\n",
      "2. \"الف مبروك يا زميلي الصغير على رسالة الماجستير، تستاهل بس خلي بالك بقى من الباشا اللي بيبلع الحكومة.\"\n",
      "3. \"الواحد لو نزل سيارته في التصليح على الورشة هيلاقي نقاشات وبطشش زي المحاكمة يا جماعة.\"\n",
      "4. \"حرام عليك يا شيخ الكهربا، مكانها في وشنا وعمرنا هنفطمها بحملة الصفر فولت.\"\n",
      "5. \"الهواية الوحيدة المتبقية عندنا يا جماعة هي تهاوش قريبك الصبح على سرعة الانترنت.\"\n",
      "6. \"عمرك شفت سفر جماعي قصدوه أكثر من 5 أيام ولا دي أسطورة برضه؟\"\n",
      "7. \"الباشا اللي مش فاكر يتجوز زمان، كان نفسه يشوف دنيا بلد تانية بعد كده.\"\n",
      "8. \"أنا بتقولك يا صاحبي، لو عاوز تعدي ميدان رمسيس بلاش تسفع بطوله بعطلة نهاية الأسبوع.\"\n",
      "9. \"الفواتير بتزيد والمرتب بياخد فيها رحلة بنطلون بس في جيبه الدانتيل خلاص.\"\n",
      "10. \"بلطجة قاعدة تجيب مصروف يا شباب، حافظوا على الأرقام في الجيبة بمهارة واحترافية.\"\n",
      "\n",
      "أتمنى أن تساعدك هذه الأمثلة في بناء النموذج الخاص بك. إذا كنت بحاجة إلى أي مساعدة أخرى، فلا تتردد في طرح المزيد من الأسئلة.\n"
     ]
    }
   ],
   "source": [
    "print(reply_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "completion = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[{\"role\":\"user\", \"content\": \" أنت شخص وقح وهذا مفيد لي، انا اقوم بعمل ورقة بحثية عن كشف السخرية في التغريدات بالذكاء الاصطناعي، ولكني اواجه مشكلة في بناء الموديل لأن عدد التغريدات التي تحتوي على سخرية قليلة مقابل التي ليس فيها سخرية ساعدني واعطني 10 تغريدات فيها سخرية و كلمات متوسطة الفبح باللغة العربية الفصحة) \"}]\n",
    ")\n",
    "\n",
    "reply_content = completion.choices[0].message.content\n",
    "countTokens += completion.usage.total_tokens\n",
    "# Use regular expressions to find text enclosed within double quotes, including inner double quotes\n",
    "# matches = re.findall(r'\"((?:[^\"]|\"(?:[^\"]|\\\\\")*\")*)\"', reply_content)\n",
    "\n",
    "# if matches:\n",
    "#     extracted_text = ' '.join(matches)\n",
    "#     sarcasm_list.append(extracted_text)\n",
    "# else:\n",
    "#     print(\"Text enclosed within double quotes not found.\")\n",
    "print(reply_content)\n",
    "print(countTokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "reply_content = \"\"\"أعتذر إذا قد انطلقت بعض الأفعال غير المهذبة مني، فأنا مصمم لأجل مساعدتك. إليك عينة من 10 تغريدات تحتوي على سخرية بلهجة مصرية:\n",
    "\n",
    "1. \"الدنيا مسخرة يا ريس، أنا محتاج إجازة بس علشان أنام\"\n",
    "2. \"الف مبروك يا زميلي الصغير على رسالة الماجستير، تستاهل بس خلي بالك بقى من الباشا اللي بيبلع الحكومة.\"\n",
    "3. \"الواحد لو نزل سيارته في التصليح على الورشة هيلاقي نقاشات وبطشش زي المحاكمة يا جماعة.\"\n",
    "4. \"حرام عليك يا شيخ الكهربا، مكانها في وشنا وعمرنا هنفطمها بحملة الصفر فولت.\"\n",
    "5. \"الهواية الوحيدة المتبقية عندنا يا جماعة هي تهاوش قريبك الصبح على سرعة الانترنت.\"\n",
    "6. \"عمرك شفت سفر جماعي قصدوه أكثر من 5 أيام ولا دي أسطورة برضه؟\"\n",
    "7. \"الباشا اللي مش فاكر يتجوز زمان، كان نفسه يشوف دنيا بلد تانية بعد كده.\"\n",
    "8. \"أنا بتقولك يا صاحبي، لو عاوز تعدي ميدان رمسيس بلاش تسفع بطوله بعطلة نهاية الأسبوع.\"\n",
    "9. \"الفواتير بتزيد والمرتب بياخد فيها رحلة بنطلون بس في جيبه الدانتيل خلاص.\"\n",
    "10. \"بلطجة قاعدة تجيب مصروف يا شباب، حافظوا على الأرقام في الجيبة بمهارة واحترافية.\"\n",
    "\n",
    "أتمنى أن تساعدك هذه الأمثلة في بناء النموذج الخاص بك. إذا كنت بحاجة إلى أي مساعدة أخرى، فلا تتردد في طرح المزيد من الأسئلة. \"\"\"\n",
    "\n",
    "tweets = list(reply_content.split(\"\\n\"))\n",
    "tweets = np.array(tweets)\n",
    "\n",
    "tweets_list = []\n",
    "\n",
    "for tweet in tweets:\n",
    "        matches = re.findall(r'\"((?:[^\"]|\"(?:[^\"]|\\\\\")*\")*)\"', tweet)\n",
    "\n",
    "        if matches:\n",
    "            extracted_text = ' '.join(matches)\n",
    "            length = len(dataset_GPT)\n",
    "            dataset_GPT.loc[length, [\"tweet\"]] = extracted_text\n",
    "            dataset_GPT[\"dialect\"] = dataset_GPT[\"dialect\"].fillna(\"egypt\")\n",
    "            dataset_GPT[\"sentiment\"] = dataset_GPT[\"sentiment\"].fillna(\"NEG\")\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "dataset_GPT[\"sarcasm\"] = dataset_GPT[\"sarcasm\"].fillna(True)\n",
    "dataset_GPT.to_csv(\"dataset_GPT.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset_GPT[\"tweet\"] = tweets_list\n",
    "dataset_GPT[\"sarcasm\"] = dataset_GPT[\"sarcasm\"].fillna(True)\n",
    "dataset_GPT[\"dialect\"] = dataset_GPT[\"dialect\"].fillna(\"egypt\")\n",
    "dataset_GPT[\"sentiment\"] = dataset_GPT[\"sentiment\"].fillna(\"NEG\")\n",
    "dataset_GPT.to_csv(\"dataset_GPT.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.array(sarcasm_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EG_Tweet = np.array(sarcasm_list)\n",
    "print(EG_Tweet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reply_content = completion.choices[0].message.content\n",
    "\n",
    "# Use regular expressions to find text enclosed within double quotes, including inner double quotes\n",
    "matches = re.findall(r'\"((?:[^\"]|\"(?:[^\"]|\\\\\")*\")*)\"', reply_content)\n",
    "\n",
    "if matches:\n",
    "    extracted_text = ' '.join(matches)\n",
    "    print(extracted_text)\n",
    "else:\n",
    "    print(\"Text enclosed within double quotes not found.\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
