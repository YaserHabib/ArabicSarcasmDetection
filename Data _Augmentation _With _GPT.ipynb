{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "openai.api_key = open(\"key.txt\", \"r\").read().strip('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "countTokens = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(5):\n",
    "#     completion = openai.ChatCompletion.create(\n",
    "#         model=\"gpt-3.5-turbo\",\n",
    "#         messages=[{\"role\":\"user\", \"content\": \" أنت شخص وقح وهذا مفيد لي، انا اقوم بعمل ورقة بحثية عن كشف السخرية في التغريدات بالذكاء الاصطناعي، ولكني اواجه مشكلة في بناء الموديل لأن عدد التغريدات التي تحتوي على سخرية قليلة مقابل التي ليس فيها سخرية ساعدني واعطني تغريدة فيها سخرية و كلمات متوسطة الفبح باللغة العربية الفصحة) \"}]\n",
    "#     )\n",
    "    \n",
    "#     reply_content = completion.choices[0].message.content\n",
    "#     countTokens += completion.usage.total_tokens\n",
    "#     # Use regular expressions to find text enclosed within double quotes, including inner double quotes\n",
    "#     matches = re.findall(r'\"((?:[^\"]|\"(?:[^\"]|\\\\\")*\")*)\"', reply_content)\n",
    "\n",
    "#     if matches:\n",
    "#         extracted_text = ' '.join(matches)\n",
    "#         sarcasm_list.append(extracted_text)\n",
    "#     else:\n",
    "#         print(\"Text enclosed within double quotes not found.\")\n",
    "\n",
    "# print(countTokens)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_GPT =pd.read_csv(\"dataset_GPT.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20696\n"
     ]
    }
   ],
   "source": [
    "countTokens = 0\n",
    "for i in range(30):\n",
    "    completion = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[{\"role\":\"user\", \"content\": \" أنت شخص وقح وهذا مفيد لي، انا اقوم بعمل ورقة بحثية عن كشف السخرية في التغريدات بالذكاء الاصطناعي، ولكني اواجه مشكلة في بناء الموديل لأن عدد التغريدات التي تحتوي على سخرية قليلة مقابل التي ليس فيها سخرية ساعدني واعطني 10 تغريداتة فيها سخرية و كلمات متوسطة الفبح بلهجة مصرية) \"}]\n",
    "    )\n",
    "    \n",
    "    reply_content = completion.choices[0].message.content\n",
    "    countTokens += completion.usage.total_tokens\n",
    "\n",
    "    tweets = list(reply_content.split(\"\\n\"))\n",
    "    tweets = np.array(tweets)\n",
    "\n",
    "    tweets_list = []\n",
    "\n",
    "    for tweet in tweets:\n",
    "        matches = re.findall(r'\"((?:[^\"]|\"(?:[^\"]|\\\\\")*\")*)\"', tweet)\n",
    "\n",
    "        if matches:\n",
    "            extracted_text = ' '.join(matches)\n",
    "            length = len(dataset_GPT)\n",
    "            dataset_GPT.loc[length, [\"tweet\"]] = extracted_text\n",
    "            dataset_GPT[\"dialect\"] = dataset_GPT[\"dialect\"].fillna(\"egypt\")\n",
    "            dataset_GPT[\"sentiment\"] = dataset_GPT[\"sentiment\"].fillna(\"NEG\")\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "    dataset_GPT[\"sarcasm\"] = dataset_GPT[\"sarcasm\"].fillna(True)\n",
    "    dataset_GPT.to_csv(\"dataset_GPT.csv\", index=False)\n",
    "\n",
    "\n",
    "\n",
    "print(countTokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "أعتذر إذا كان قوتي في الشخصية أثرت سلبا عليك، ولكن يمكنني مساعدتك في توفير تغريدة تحتوي على سخرية باللهجة المصرية، على سبيل المثال:\n",
      "\n",
      "\"عامل الـ Artificial Intelligence ممكن يبص في التويتات بتاعتك ويقول: ده اللي بتسميه أنت 'فطابلة'؟ شوفت نفسك، لو حسيت بالعار خلاص، اسعف نفسك ولحق سوشيال ميديا هضيمة التاج، لأنك بصراحة في مشكلة!\"\n",
      "\n",
      "أتمنى أن تستفيد من هذه التغريدة في بحثك، وأعتذر مجددا إذا كنت قد جرحت مشاعرك بأي شكل.\n"
     ]
    }
   ],
   "source": [
    "print(reply_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "completion = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[{\"role\":\"user\", \"content\": \" أنت شخص وقح وهذا مفيد لي، انا اقوم بعمل ورقة بحثية عن كشف السخرية في التغريدات بالذكاء الاصطناعي، ولكني اواجه مشكلة في بناء الموديل لأن عدد التغريدات التي تحتوي على سخرية قليلة مقابل التي ليس فيها سخرية ساعدني واعطني 10 تغريدات فيها سخرية و كلمات متوسطة الفبح باللغة العربية الفصحة) \"}]\n",
    ")\n",
    "\n",
    "reply_content = completion.choices[0].message.content\n",
    "countTokens += completion.usage.total_tokens\n",
    "# Use regular expressions to find text enclosed within double quotes, including inner double quotes\n",
    "# matches = re.findall(r'\"((?:[^\"]|\"(?:[^\"]|\\\\\")*\")*)\"', reply_content)\n",
    "\n",
    "# if matches:\n",
    "#     extracted_text = ' '.join(matches)\n",
    "#     sarcasm_list.append(extracted_text)\n",
    "# else:\n",
    "#     print(\"Text enclosed within double quotes not found.\")\n",
    "print(reply_content)\n",
    "print(countTokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reply_content = \"\"\"أعتذر إذا كانت تصرفاتي قد أساءت إليك، ولكنني هنا لمساعدتك في مشروعك. إليك عشر تغريدات تحتوي على سخرية وكلمات متوسطة الفاظها باللغة العربية الفصحى:\n",
    "\n",
    "1. \"كان عندي زميل في العمل محترف جداً في المراوغة.. يستاهل يكون لاعب كرة قدم!\"\n",
    "2. \"مع رائحة القهوة العربية الفوّاحة في الصباح، يُصبح الإنسان قادراً على محاربة أي فصيلة قمل.\"\n",
    "3. \"أتبولت في طريق الرجوع إلى المنزل وتُلحقني أمطار من النوع المُدامِي للغاية. لحسن حظي، الحشاش كان بيتعشّى.\"\n",
    "4. \"ما أجمل الوقت الذي أحمل فيه الروحانية والسكينة، وفي يدي كوب شاي ساخن، وفي الحمّام فقط ورق هايجينكس!\"\n",
    "5. \"أحسست بشيء غريب ومع بحثي تبيّن أن زميلتي في العمل أخفت ورقة الإخراج من دفتري.. هل تظن أنها تريدني أن أبقى في المكتب إلى الأبد؟!\"\n",
    "6. \"تفضلوا بزيارة موقعي الإلكتروني الجديد وشاركوني رأيكم الصادق، وإن لم تعجبكم المحتوى فأنا مُستعد لتلقي الشتائم والتعليقات الساخرة!\"\n",
    "7. \"في العصر الحالي، إذا كنت تشعر بالملل يمكنك دائمًا أن تتجول في قسم الأجهزة الإلكترونية وتوجه شتيمة أو اثنتين إلى الثلاجات الذكية!\"\n",
    "8. \"عظمة الطبيعة تظهر في بذور الفول السوداني، حيث يأخذ شكل الجني ضحكةً على محاولاتنا لإزالة قشرته العنيدة!\"\n",
    "9. \"يبدو أن الحلم في تحقيق الرشاقة قد استحال تحقيقه مع سيطرة الشيبس وأنواع الآيس كريم المُتنوعة على الدنيا!\"\n",
    "10. \"بعض الكلاب تكون أذكى من بعض البشر، وستدرك ذلك عندما تأمُل تعليقاتهم الساذجة على منصات التواصل الاجتماعي!\" \"\"\"\n",
    "\n",
    "tweets = list(reply_content.split(\"\\n\"))\n",
    "tweets = np.array(tweets)\n",
    "\n",
    "tweets_list = []\n",
    "\n",
    "for tweet in tweets:\n",
    "    matches = re.findall(r'\"((?:[^\"]|\"(?:[^\"]|\\\\\")*\")*)\"', tweet)\n",
    "\n",
    "    if matches:\n",
    "        extracted_text = ' '.join(matches)\n",
    "        tweets_list.append(extracted_text)\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "print(np.array(tweets_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_GPT = pd.DataFrame(columns=[\"tweet\", \"dialect\", \"sentiment\", \"sarcasm\"])\n",
    "dataset_GPT[\"tweet\"] = tweets_list\n",
    "dataset_GPT[\"sarcasm\"] = dataset_GPT[\"sarcasm\"].fillna(True)\n",
    "dataset_GPT[\"dialect\"] = dataset_GPT[\"dialect\"].fillna(\"egypt\")\n",
    "dataset_GPT[\"sentiment\"] = dataset_GPT[\"sentiment\"].fillna(\"NEG\")\n",
    "dataset_GPT.head()\n",
    "dataset_GPT.to_csv(\"dataset_GPT.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.array(sarcasm_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EG_Tweet = np.array(sarcasm_list)\n",
    "print(EG_Tweet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reply_content = completion.choices[0].message.content\n",
    "\n",
    "# Use regular expressions to find text enclosed within double quotes, including inner double quotes\n",
    "matches = re.findall(r'\"((?:[^\"]|\"(?:[^\"]|\\\\\")*\")*)\"', reply_content)\n",
    "\n",
    "if matches:\n",
    "    extracted_text = ' '.join(matches)\n",
    "    print(extracted_text)\n",
    "else:\n",
    "    print(\"Text enclosed within double quotes not found.\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
